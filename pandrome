#!/usr/bin/perl

=pod

=head1 NAME

pandrome -- Generate palindromic pangrams

=head1 USAGE

	pandrome [--optimize size|speed] [--verbose] wordfiles
	pandrome --version

=head1 DESCRIPTION

pandrome generates "palindromic pangrams", palindromes which use all 26 letters
of the English alphabet.

The input is a list of the words which may be used to construct the output.
Any arguments remaining on the command line after option processing will
be interpreted as paths to files containing words, one word per line.
Comments and blank lines are not allowed.  If multiple files are specified,
words will be taken from all of them.  If no word files are specified, data
will be taken from standard input.

The palindromic pangram is written to standard output.

The first time the program is executed with a given word list, it will be
several minutes slower than successive executions.  It is spending this time
converting the flat word list into the data structures it uses; these
structures are then written to a cache in C<~/.pandrome>.

Options:

=over 4

=item --optimize (-o) I<size|speed>

If set to C<size>, the program will take extra time to find shorter pangrams,
both in terms of number of letters and number of words (although we are biased
in favor of fewer letters over fewer words.)
The default is C<speed>.  Note that parameter only tunes the program slightly;
C<speed> will still find fairly good results, and C<size> will still run
rather quickly.

=item --verbose (-v)

This option causes progress information to be written to standard error.
It can be specified multiple times to increase the amount of information
displayed; values greater than 1 are probably only useful for debugging
the program.

=item --version (-V)

If this option is specified, the program's version will be written to standard
output and the program will exit immediately.

=back

=head1 FILES

~/.pandrome

=head1 ALGORITHM

The program focuses on obtaining good results extremely quickly; it never backtracks
unless absolutely necessary, and it doesn't do anything too time-consuming
when ordering the list of successor states.  Better results can be obtained via
a more AI-esque approach.

=head2 DATA STRUCTURES

pandrome makes heavy use of tries.  A trie is a tree which stores the label
for a vertex in the path to reach that vertex; so, "foo" would be a node
at depth 3, f-E<gt>o-E<gt>o.  We use two tries, one containing all of the
words in the word list (the prefix trie) and one containing all of the 
words backwards (the suffix trie).  This lets us quickly get a list of all
words which start or end with a given string.  Our tries are implemented
as a custom subclass of the CPAN module C<Tree::Trie>; see
the comments at the top of C<PandromeTrie.pm> for more details.

We keep track of the solution as a list of "head" words that will go at the
beginning and a list of "tail" words that will go at the end.  As we build
the palindrome, we insert a word at one end, and then we insert a sequence
of words at the other end which begin with the backwards version of that word.
If we started by inserting C<panama> at the end, the next move would be to
insert a word at the beginning.  Ideally, we'd like something which starts
with the string C<amanap>, but if no such word exists (how unlikely!),
we'll try C<amana>, C<aman>, C<ama>, C<am>, C<a>, and if none of those
work we'll give up and decide that C<panama> wasn't a good word to insert
at the end after all.

=head2 WORD SELECTION

How well the program performs is determined by how cleverly it can pick
the next word to insert.  When preparing to insert a word into the solution, we
generate the list of all possible successor words, and sort it by, in
descending order of importance:

=over 4

=item 1.

Is the word long enough to match the text that it needs to match?
If the head of the solution is C<foos> and the tail is C<of>,
we still need to insert another word at the beginning of the tail
which ends with C<so> in order to have the anagram be balanced.
So, in this case, we would prefer that our matches be at least two
letters long.

=item 2.

How good does it look like the word will be?  The heuristic function we use
here takes into account:

=over 4

=item *

Whether the word is reversible; that is, after balancing the current solution,
can the leftover letters be flipped to form another valid word?  This lets
use prefer C<birds> to C<wounds> when balancing out a head that starts with
C<sd>; the C<ds> goes to balance the solution, and then the head needs to
start with C<rib>.  Because C<rib> is a valid word, we can simply use that,
and then we have a completely balanced anagram and can pick whatever we want
for our next word, letting us get rid of some tricky letters.

=item *

How many letters that aren't in the solution will the word provide?
Rarer letters are weighted more favorably.

=item *

How many rare letters that we I<have> already seen does the word have?  Rare
letters make it harder to balance the anagram, since it's trickier to find
words which contain them and meet all the other criteria.

=item *

How long is the word?  This criterion is only used when optimizing for size.

=back

The different factors may have different weights, depending on optimization
settings.  These values were determined empirically.

=item 3.

As a tie-breaker, the words are lexically sorted.

=back

=head2 Q OPTIMIZATION

C<q> is the most troublesome letter.  Not only is it extremely rare -- there
are only 2541 words which contain it in the 173,528-word sample word list --
but there are only 30 words in the sample list which contain it without
it being followed immediately by a C<u>.  This makes it reasonably easy to get
C<q> in one direction, by using a C<qu>-word, but then it's extremely
difficult to balance it in the other direction.  We do some tricks to get this
over with as quickly as possible.

We start the anagram by picking a word containing a C<q>.  When optimizing
for speed, we just pick a word containing C<uq>.  This ensures that balancing
it requires the comparatively simple task of finding a suitable C<qu>-word.
When optimizing for size, we try starting with words that contain a C<q>
but I<not> a C<u>, sorted in order of how probable their letters are; this
maximizes our flexibility while getting rid of the pesky C<q>, but if that
doesn't work, we fall back on starting with words that start or end with
C<q> or words which contain C<uq>.

=head1 FUTURE DIRECTIONS

L<http://www.32768.com/bill/weblog/2003/07/11/some-programming-problems-at-ita-software/>
has a number of solutions which are shorter than the ones typically generated
by this program (I didn't use any of the data from this page in developing the
program, but I was curious as to how optimal my output was, so I Googled a bit.
--MS)  One specific thing that some of their best answers have is a 'q' in the
middle of their odd-length palindrome.  I don't attempt to take advantage of
the special characteristic of the center, and adding the ability to build
out from the center would require non-trivial changes to the program.

I spent some time tuning a few of the parameters and playing with some
different ways to use the data I already have available, but I didn't do
this extensively.  A genetic algorithm, or simply more time, might find
a better set of weights for the successor-scoring function, for instance.
I did experiment briefly with utilizing bigram probabilities in addition to
unigram probabilities, but that produced worse output and took longer to do it.

=head1 BUGS

Of course not, who would submit code that had any bugs for a job application?

=head1 HISTORY

Written 2006-11-13 for ITA Software's job application.

=head1 AUTHOR

Matthew Sachs E<lt>matthewg@zevils.comE<gt>
L<http://www.zevils.com/misc/resume.html>

=cut

use strict;
use warnings;
use Getopt::Long;
use Data::Dumper; #For debugging
use Storable qw(nstore retrieve fd_retrieve dclone); #For caching (and state cloning)
use Digest::MD5 qw(md5_hex);
use IO::Scalar;
use User::pwent;
use FindBin qw($Bin);
use lib "$Bin";
use PandromeTrie;

eval {
	require List::Util;
	List::Util->import(qw(shuffle sum));
};
if($@) {
	die "Error while loading List::Util:\n$@\n" .
	    "Either download it from CPAN or use a perl newer than 5.007.\n";
}

my $VERSION = '$Revision$';
our($OPTIMIZE, $VERBOSE) = ("speed", 0);
Getopt::Long::Configure("bundling");
my $opts_ok = GetOptions(
	"optimize|o=s" => sub {
		my($arg, $val) = @_;
		die "Invalid value for $arg!\n"
		   unless $val =~ /^(speed|size)$/;
		$OPTIMIZE = $val;
	},
	"version|V" => sub {
		print "pandrome $VERSION\n" .
		      "Matthew Sachs <matthewg\@zevils.com>\n";
		exit 0;
	},
	"verbose|v+" => \$VERBOSE,
);
if(!$opts_ok) {
	warn "Usage: pandrome [--optimize words|letters] [--verbose] wordlist\n";
	exit 1;
}

sub word_to_chars { split(//, shift || ""); }
sub reverse_word { join("", reverse(word_to_chars(shift))); }
sub random_element {
	my $list = shift;
	$list->[int(rand(@$list))];
}
# Do something for all letters in a word
sub do_unigrams {
	my($word, $unifunc) = @_;
	$unifunc->($_) foreach word_to_chars($word);
}

sub get_wordlist {
	warn "Reading word list...\n" if $VERBOSE;
	local $/ = undef;
	my $wordlist = join("", <>);

	my $digest = md5_hex($wordlist);
	my $cache_dir = (getpwuid($>)->dir)."/.pandrome";
	if(! -d $cache_dir and !mkdir($cache_dir)) {
		warn "Could not create cache directory: $!\n";
	} else {
		if(-f "$cache_dir/$digest") {
			my $ret;
			eval { $ret = retrieve("$cache_dir/$digest"); };
			if(!$ret || $@) {
				warn "Couldn't load cache: $@\n";
			} else {
				return $ret;
			}
		}
	}

	my(%unigram_frequencies);
	my($unigram_count) = (0);
	my($prefixes, $suffixes) = (PandromeTrie->new(), PandromeTrie->new());
	my(%words, %uq_words, %q_no_u_words);
	foreach my $word (split(/\n/, $wordlist)) {
		chomp $word;

		$words{$word} = 1;
		# 'q' is very hard, because it is almost always followed by 'u',
		# and if we have a 'qu' word, we then need a 'uq' word to
		# form the anagram.  So, we build up a special list of words
		# which contain that bigram.  Words with a 'q' but no 'u' are
		# also helpful.
		$uq_words{$word} = 1 if $word =~ /uq/;
		$q_no_u_words{$word} = 1 if $word =~ /q(?!u)/;

		do_unigrams($word, sub {
			my $gram = shift; #It's better than a damn!
			$unigram_frequencies{$gram}++;
			$unigram_count++;
		});

		$prefixes->add($word);
		$suffixes->add(reverse_word($word));
	}
	warn "Done, writing cache.\n" if $VERBOSE;

	my %unigram_probs = map {
		$_ => $unigram_frequencies{$_} / $unigram_count;
	} keys %unigram_frequencies;

	my $ret = {
		unigram_probs => \%unigram_probs,
		prefixes => $prefixes,
		suffixes => $suffixes,
		words => \%words,
		uq_words => \%uq_words,
		q_no_u_words => \%q_no_u_words,
	};
	my $ok;
	eval { $ok = nstore($ret, "$cache_dir/$digest"); };
	warn "Couldn't write cache: $@\n" if !$ok || $@;
	warn "Wrote cache.\n" if $VERBOSE;
	return $ret;
}
my $word_data = get_wordlist();
my %words = %{$word_data->{words}};
my %unigram_probs = %{$word_data->{unigram_probs}};
#die Data::Dumper::Dumper(\%unigram_probs);


my $state = {
	letters_needed => {map {$_ => 1} 'a'..'z'},
	solution_head => [],
	solution_tail => [],
	solution_length => 0,
	bad_moves => {},
	unmatched_head => "",
	unmatched_tail => "",
	successor_data => {},
};

# Force dealing with q at the start, it's the most difficult by far.
# Easiest ones are the ones that end with 'q', and longer ones are easier
# than shorter ones.  In my testing, this sped things up by a factor of 200
# over starting with an arbitrary word.  We seem to get the shortest results
# by having the q-word start at the end, but the fastest by having it start
# at the beginning.
my @q_words;
if($OPTIMIZE eq "speed") {
	@q_words = shuffle(keys(%{$word_data->{uq_words}}));
} else {
	# If this looks like line noise, see
	# <http://en.wikipedia.org/wiki/Schwartzian_Transform>.
	@q_words =
		(map {
			$_->[0]
		} sort { 
			length($a->[0]) <=> length($b->[0])
				or
			$b->[1] <=> $a->[1]
				or
			$a->[0] cmp $b->[0]
		} map {
			my $score = 0;
			do_unigrams($_, sub {
				my $letter = shift;
				$score += $unigram_probs{$letter};
			});
			$score /= length($_);
			[$_, $score]
		} keys(%{$word_data->{q_no_u_words}})),
		(map {reverse_word($_)} $word_data->{suffixes}->lookup("q")),
		shuffle(
			keys(%{$word_data->{uq_words}}),
			$word_data->{prefixes}->lookup("q")
		)
}
$state->{successor_data} = {
	words => [@q_words],
	trie => $OPTIMIZE eq "speed" ?
		$word_data->{prefixes} :
		$word_data->{suffixes},
	reversed => $OPTIMIZE ne "speed",
	unmatched => ""
};

my @state_stack;
sub use_word {
	my($word, $tail) = @_;
	warn "Using $word\n" if $VERBOSE;
	$tail ||= 0;

	# Don't copy the successor data, successor states don't have the same
	# successors!
	my $sdata = delete $state->{successor_data};
	my $new_state = dclone($state);
	$state->{successor_data} = $sdata;
	# This makes it easy to backtrack.
	push @state_stack, $state;
	$state = $new_state;

	warn "...State cloned.\n" if $VERBOSE > 1;

	$state->{last_move} = $word;
	delete $state->{letters_needed}->{$_} foreach word_to_chars($word);
	$state->{solution_length} += length($word);
	# To stay out of infinite loops, don't use the same word twice.
	$state->{bad_moves}->{$word} = 1;

	# Now figure out how much of the unmatched bit we've matched.
	# We take the larger one and remove the smaller one from 
	# either the beginning or end.
	my($unmatched, $nextmatch, $match_tail);
	if($tail) {
		unshift @{$state->{solution_tail}}, $word;
		$unmatched = \$state->{unmatched_tail};
		$nextmatch = \$state->{unmatched_head};
	} else {
		push @{$state->{solution_head}}, $word;
		$unmatched = \$state->{unmatched_head};
		$nextmatch = \$state->{unmatched_tail};
	}
	$$unmatched ||= "";
	if(length($word) >= length($$unmatched)) {
		$word = reverse_word($word) if !$tail;
		$$nextmatch = substr(
			$word,
			0,
			length($word) - length($$unmatched));
		$$nextmatch = reverse_word($$nextmatch);
		$$unmatched = "";
	} else {
		$word = reverse_word($word) if $tail;
		$$unmatched =~ s/^$word//;
	}

	warn Data::Dumper->Dump([$state], ["state"]), "\n" if $VERBOSE > 2;
}
sub backtrack {
	my $last_move = $state->{last_move};
	warn "Retracting $last_move\n" if $VERBOSE;
	$state = pop @state_stack;
	#$state->{bad_moves}->{$last_move} = 1 if $last_move;

	if($VERBOSE > 2) {
		my $sdata = delete $state->{successor_data};
		warn Data::Dumper->Dump([$state], ["state"]), "\n";
		$state->{successor_data} = $sdata;
	}
}
sub solution {
	join(" ", @{$state->{solution_head} || []}, @{$state->{solution_tail} || []});
}

GET_MOVE: while(1) {
	my $unmatched_data = $state->{unmatched_tail} || $state->{unmatched_head};
	if(
		(keys(%{$state->{letters_needed}}) == 0) and
		(!$unmatched_data
			or
			(length($unmatched_data) == 1
				and
			not $state->{solution_length} % 2)
		)
	) {
		last;
	}

	my(%successor_data, $word);
	if(!$state->{successor_data}) {
		warn "Generating successor data...\n" if $VERBOSE > 1;
		$successor_data{reversed} = 0;		
		if($state->{unmatched_tail}) {
			$successor_data{unmatched} = \"$state->{unmatched_tail}";
			$successor_data{trie} = $word_data->{suffixes};
			$successor_data{reversed} = 1;
		} elsif($state->{unmatched_head}) {
			$successor_data{unmatched} = \"$state->{unmatched_head}";
			$successor_data{trie} = $word_data->{prefixes};
		} else {
			# No remaining prefixes or suffixes.
			# Find a word that starts with a letter we need...
			$successor_data{trie} = $word_data->{prefixes};
			foreach my $letter (shuffle('a'..'z')) {
				# 'a' isn't really such a great starting letter.
				# Not too many words end with it.
				# So, pick a random (unused) one.
				next unless $state->{letters_needed}->{$letter};
				$successor_data{unmatched} = \"$letter";
				warn "No unmatched data, picking unused letter '$letter'\n" if $VERBOSE;
				last;
			}
			last unless $successor_data{unmatched}; #We're done!
		}

		$successor_data{unmatched} ||= \"";
		my $unmatched = $successor_data{unmatched};

		my $state_desc = "";
		if($VERBOSE > 1) {
			$state_desc = sprintf "(%s) {%s} [%s%s]",
				solution(),
				join("", keys %{$state->{letters_needed}}),
				($state->{unmatched_tail} ? ">" : "<"),
				$state->{unmatched_tail} || $state->{unmatched_head} || "";
		}

		warn "Looking up $$unmatched $state_desc\n" if $VERBOSE;
		my $letters_needed = keys(%{$state->{letters_needed}});
		my $unmatched_length = length($$unmatched);

		print STDERR "Generating candidates... " if $VERBOSE > 1;
		my @unsorted_candidates = $successor_data{trie}->lookup($$unmatched);
		if($successor_data{reversed}) {
			@unsorted_candidates = map {reverse_word($_)} @unsorted_candidates;
		}
		print STDERR scalar(@unsorted_candidates) . "\n" if $VERBOSE > 1;
		my %letters_needed = %{$state->{letters_needed}};

		# For sorting the words, we want to know if the word,
		# after removing the bit which is needed to counter
		# whatever text is "unmatched", is reversible.  So,
		# if so far we have "a man * panama", the "pa" in the tail
		# has not yet been matched by an "ap" in the head.  We'd
		# ideally like a word that, after removing the prefix
		# ap, can have its remainder reversed to form another valid
		# word.  We turn off warnings for this function because it's
		# okay to have the substr go beyond the string.
		my $remove_unmatched;
		if($successor_data{reversed}) {
			$remove_unmatched = sub {
				no warnings;
				substr(shift, 0, -$unmatched_length);
			};
		} else {
			$remove_unmatched = sub {
				no warnings;
				my $w = substr(shift, $unmatched_length);
				reverse_word($w);
			};
		}

		$successor_data{words} = [map {
			$_->[0]
		} sort {
			$b->[2] <=> $a->[2] # Long enough
				or
			$b->[1] <=> $a->[1] # Score
				or
			$a->[0] cmp $b->[0] # Lexical sort of words
		} map {
			my $the_word = $_;
			my $length = length($the_word);
			my $no_unmatched = $remove_unmatched->($the_word);
			my $reversible = !$no_unmatched || exists(
				$words{$no_unmatched}
			);
			my $score;

			# unneeded_score:
			#	If we're going to be taking words that
			#	contain letters which are already in the
			#	solution, we'd prefer that they be common
			#	letters because it's easier to find balancing
			#	words with them.
			# needed_score:
			#	How improbable are the distinct letters that 
			#	this word has which aren't yet in the solution?
			#	The more improbable the better.
			# Both of these are normalized to the length of the
			# word.

			if($letters_needed) {
				my $unneeded_score = 0;
				my %has_needed;
				do_unigrams($the_word, sub {
					my $letter = shift;
					if($letters_needed{$letter}) {
						$has_needed{$letter} = 
						   1 - $unigram_probs{$letter};
					} else {
						$unneeded_score += 
						    $unigram_probs{$letter};
					}
				});
				my $needed_score = sum(values %has_needed) || 0;
				$needed_score /= $length;
				$unneeded_score /= $length;
				# Weights determined empirically.
				if($OPTIMIZE eq "speed") {
					$score =
						$reversible +
						$needed_score +
						$unneeded_score;
				} else {
					$score =
						2*$reversible +
						$needed_score +
						$unneeded_score -
						$length/3;
				}
			} else {
				# We don't need any more letters, take the shortest.
				$score = $reversible + 1/$length;
			}
			[
				$the_word,
				$score,
				$length >= $unmatched_length,
			];
		} @unsorted_candidates];
		$state->{successor_data} = \%successor_data;
	} else {
		warn "Using cached successor data (we retracted)...\n" if $VERBOSE > 1;
		%successor_data = %{$state->{successor_data}};
	}

	my $trie = $successor_data{trie};
	my $unmatched = $successor_data{unmatched};
	my $reversed = $successor_data{reversed};
	my $words = $successor_data{words};

	while(@$words) {
		my $word_candidate = shift @$words;
		next if $state->{bad_moves}->{$word_candidate};
		$word = $word_candidate;
		last;
	}

	if(!$word) {
		warn "...No appropriate words!\n" if $VERBOSE > 1;
		backtrack();
		redo GET_MOVE;
	}

	use_word($word, $reversed);
}

my $sol = solution();
print $state->{solution_length}, ": ";
print solution(), "\n";
